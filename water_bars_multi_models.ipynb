{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beddeb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.signal import savgol_filter\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from Load_data import Data_from_nc\n",
    "import xarray as xr\n",
    "import math\n",
    "import gc\n",
    "from scipy.stats import linregress\n",
    "from scipy import stats\n",
    "from typing import Sequence, Tuple\n",
    "from typing import Dict, Tuple\n",
    "# ─── I/O Helpers ────────────────────────────────────────────────────────────\n",
    "\n",
    "def get_data_from_mat_for_calcu(file, variable):\n",
    "    var_dict = scio.loadmat(file)\n",
    "    var = var_dict[variable]\n",
    "    var = var[:, 29:]\n",
    "    return var.T\n",
    "\n",
    "def get_data_from_nc(file, variable):\n",
    "    file_obj = nc.Dataset(file)\n",
    "    data = file_obj.variables[variable]\n",
    "    var_data = np.array(data)\n",
    "    var_data = var_data[:, 29:, :]\n",
    "    var_data[var_data > 1000000] = np.nan\n",
    "    var_data = np.squeeze(var_data)\n",
    "    return var_data\n",
    "\n",
    "def get_data_from_mat(file, variable):\n",
    "    var_dict = scio.loadmat(file)\n",
    "    var = var_dict[variable]\n",
    "    var = var[:, 29:] \n",
    "    return var\n",
    "\n",
    "str_base = '' #TODO \n",
    "ar6_region = get_data_from_mat_for_calcu(str_base + '/plotting_tools/ar6_region.mat','ar6_region')\n",
    "AREA = get_data_from_mat(str_base + '/plotting_tools/AREA.mat', 'AREA') # Area for CLM_data\n",
    "irr_diff = get_data_from_mat_for_calcu(str_base + '/plotting_tools/irr_diff_out.mat', 'irr_diff_out')\n",
    "\n",
    "# ─── Model‐specific loader ──────────────────────────────────────────────────\n",
    "# Here we have a function for each ESM to read the variable\n",
    "# This is because the folders and the names are all model-specific\n",
    "def get_data_cesm2(variable):\n",
    "    \n",
    "    str_start = '/water_fluxes/CESM2/CESM2_'\n",
    "    str_mid = '_1901_2014_'\n",
    "    str_end = '_yearmean'\n",
    "    \n",
    "    data_irr01 = get_data_from_nc(str_base + str_start + 'IRR01' + str_mid + variable + str_end, variable)\n",
    "    data_noi01 = get_data_from_nc(str_base + str_start + 'NOI01' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr02 = get_data_from_nc(str_base + str_start + 'IRR02' + str_mid + variable + str_end, variable)\n",
    "    data_noi02 = get_data_from_nc(str_base + str_start + 'NOI02' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr03 = get_data_from_nc(str_base + str_start + 'IRR03' + str_mid + variable + str_end, variable)\n",
    "    data_noi03 = get_data_from_nc(str_base + str_start + 'NOI03' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr = (data_irr01 + data_irr02 + data_irr03) / 3 * 365 * 86400\n",
    "    data_noi = (data_noi01 + data_noi02 + data_noi03) / 3 * 365 * 86400\n",
    "    \n",
    "    return data_irr[:-1,:,:], data_noi[:-1,:,:]\n",
    "\n",
    "def get_data_e3sm(variable3):\n",
    "    \n",
    "    str_start = '/water_fluxes/E3SMv2/E3SM_'\n",
    "    str_mid = '_1901_2014_'\n",
    "    str_end = '_yearmean_0.9x1.25'\n",
    "    \n",
    "    data_irr01 = get_data_from_nc(str_base + 'IRR01' + str_mid + variable3 + str_end, variable3)\n",
    "    data_noi01 = get_data_from_nc(str_base + 'NOI01' + str_mid + variable3 + str_end, variable3)\n",
    "\n",
    "    data_irr02 = get_data_from_nc(str_base + 'IRR02' + str_mid + variable3 + str_end, variable3)\n",
    "    data_noi02 = get_data_from_nc(str_base + 'NOI02' + str_mid + variable3 + str_end, variable3)\n",
    "\n",
    "    data_irr = (data_irr01 + data_irr02) / 2 * 365 * 86400\n",
    "    data_noi = (data_noi01 + data_noi02) / 2 * 365 * 86400\n",
    "\n",
    "    return data_irr[6:-1,:,:], data_noi[6:-1,:,:]\n",
    "\n",
    "def get_data_cesm2_gw(variable):\n",
    "    \n",
    "    str_start = '/water_fluxes/CESM2_gw/CESM2_gw_'\n",
    "    str_mid = '_1901_2014_'\n",
    "    str_end = '_yearmean'\n",
    "    \n",
    "    data_irr01 = get_data_from_nc(str_base + str_start + 'IRR01' + str_mid + variable + str_end, variable)\n",
    "    data_noi01 = get_data_from_nc(str_base + str_start + 'NOI01' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr02 = get_data_from_nc(str_base + str_start + 'IRR02' + str_mid + variable + str_end, variable)\n",
    "    data_noi02 = get_data_from_nc(str_base + str_start + 'NOI02' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr03 = get_data_from_nc(str_base + str_start + 'IRR03' + str_mid + variable + str_end, variable)\n",
    "    data_noi03 = get_data_from_nc(str_base + str_start + 'NOI03' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr = (data_irr01 + data_irr02 + data_irr03) / 3 * 365 * 86400\n",
    "    data_noi = (data_noi01 + data_noi02 + data_noi03) / 3 * 365 * 86400\n",
    "    \n",
    "    return data_irr[:-1,:,:], data_noi[:-1,:,:]\n",
    "    \n",
    "def get_data_noresm(variable):\n",
    "    \n",
    "    str_start = '/water_fluxes/NorESM2/NorESM_'\n",
    "    str_mid = '_1901_2014_'\n",
    "    str_end = '_yearmean'\n",
    "    \n",
    "    data_irr01 = get_data_from_nc(str_base + str_start + 'IRR01' + str_mid + variable + str_end, variable)\n",
    "    data_noi01 = get_data_from_nc(str_base + str_start + 'NOI01' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr02 = get_data_from_nc(str_base + str_start + 'IRR02' + str_mid + variable + str_end, variable)\n",
    "    data_noi02 = get_data_from_nc(str_base + str_start + 'NOI02' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr03 = get_data_from_nc(str_base + str_start + 'IRR03' + str_mid + variable + str_end, variable)\n",
    "    data_noi03 = get_data_from_nc(str_base + str_start + 'NOI03' + str_mid + variable + str_end, variable)\n",
    "\n",
    "    data_irr01_temp = np.zeros([116,163,288])# the first year of ensemble 01 is missing\n",
    "    data_irr01_temp[1:, :, :] = data_irr01\n",
    "    data_irr01_temp[0, :, :] = (data_irr02[0, :, :] + data_irr03[0, :, :])/2\n",
    "    data_irr01 = data_irr01_temp\n",
    "    \n",
    "    data_irr = (data_irr01 + data_irr02 + data_irr03) / 3 * 365 * 86400\n",
    "    data_noi = (data_noi01 + data_noi02 + data_noi03) / 3 * 365 * 86400\n",
    "    \n",
    "    return data_irr[1:-1,:,:], data_noi[1:-1,:,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_data_ipsl(variable2):\n",
    "    \n",
    "    str_start = '/water_fluxes/IPSL-CM6/'\n",
    "    str_end = '_1901_2014_Month.nc_yearmean_0.9x1.25'\n",
    "    \n",
    "    data_irr = get_data_from_nc(str_base + str_start + 'IRR01_'+ variable2 + str_end, variable2)\n",
    "    data_noi = get_data_from_nc(str_base + str_start + 'NOI01_'+ variable2 + str_end, variable2)\n",
    "\n",
    "\n",
    "    data_irr = data_irr * 365 * 86400\n",
    "    data_noi = data_noi * 365 * 86400\n",
    "\n",
    "    return data_irr, data_noi\n",
    "\n",
    "def get_data_cnrm(variable2):\n",
    "    \n",
    "    str_start = '/water_fluxes/CNRM-CM6-1/'\n",
    "    \n",
    "    str_end = '.nc_yearmean_yearmean_0.9x1.25'\n",
    "    \n",
    "    data_irr01 = get_data_from_nc(str_start + variable2 + '_IRR01' + str_end, variable2)\n",
    "    data_noi01 = get_data_from_nc(str_start + variable2 + '_NOI01' + str_end, variable2)\n",
    "\n",
    "    data_irr02 = get_data_from_nc(str_start + variable2 + '_IRR02' + str_end, variable2)\n",
    "    data_noi02 = get_data_from_nc(str_start + variable2 + '_NOI02' + str_end, variable2)\n",
    "\n",
    "    data_irr03 = get_data_from_nc(str_start + variable2 + '_IRR03' + str_end, variable2)\n",
    "    data_noi03 = get_data_from_nc(str_start + variable2 + '_NOI03' + str_end, variable2)\n",
    "\n",
    "    data_irr04 = get_data_from_nc(str_start + variable2 + '_IRR04' + str_end, variable2)\n",
    "    data_noi04 = get_data_from_nc(str_start + variable2 + '_NOI04' + str_end, variable2)\n",
    "\n",
    "    data_irr05 = get_data_from_nc(str_start + variable2 + '_IRR05' + str_end, variable2)\n",
    "    data_noi05 = get_data_from_nc(str_start + variable2 + '_NOI05' + str_end, variable2)\n",
    "\n",
    " \n",
    "    \n",
    "    data_irr = (data_irr01+data_irr02+data_irr03+data_irr04+data_irr05) / 5 * 365 * 86400\n",
    "    data_noi = (data_noi01+data_noi02+data_noi03+data_noi04+data_noi05) / 5 * 365 * 86400\n",
    "\n",
    "    return data_irr, data_noi\n",
    "    \n",
    "    \n",
    "def get_data_miroc(variable):\n",
    "    \n",
    "    str_start = '/water_fluxes/MIROC-INTEG-ES/'\n",
    "    \n",
    "    str_mid = '_mon_MIROC_'\n",
    "    str_end = '_1901-2014.nc_0.9x1.25_yearmean'\n",
    "    \n",
    "    data_irr01 = get_data_from_nc(str_start + 'tranirr-01' + variable + str_mid + 'IRR01' + str_end, variable)\n",
    "    data_noi01 = get_data_from_nc(str_start + '1901irr-01' + variable + str_mid + 'NOI01' + str_end, variable)\n",
    "\n",
    "    data_irr02 = get_data_from_nc(str_start + 'tranirr-02' + variable + str_mid + 'IRR02' + str_end, variable)\n",
    "    data_noi02 = get_data_from_nc(str_start + '1901irr-02' + variable + str_mid + 'NOI02' + str_end, variable)\n",
    "\n",
    "    data_irr03 = get_data_from_nc(str_start + 'tranirr-03' + variable + str_mid + 'IRR03' + str_end, variable)\n",
    "    data_noi03 = get_data_from_nc(str_start + '1901irr-03' + variable + str_mid + 'NOI03' + str_end, variable)\n",
    "\n",
    "    data_irr = (data_irr01 + data_irr02 + data_irr03) / 3 * 365 * 86400\n",
    "    data_noi = (data_noi01 + data_noi02 + data_noi03) / 3 * 365 * 86400\n",
    "    \n",
    "    return data_irr, data_noi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd79f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOADERS = {\n",
    "    'CESM2':    get_data_cesm2,\n",
    "    'CESM2_gw': get_data_cesm2_gw,\n",
    "    'NorESM':   get_data_noresm,\n",
    "    'E3SM':     get_data_e3sm,\n",
    "    'IPSL':     get_data_ipsl,\n",
    "    'CNRM':     get_data_cnrm,\n",
    "    'MIROC':    get_data_miroc,\n",
    "}\n",
    "\n",
    "\n",
    "# specify per-model which variable names to fetch\n",
    "# tuple of (rain_var, snow_var) means load both and sum\n",
    "# single-member tuple means loader returns P directly\n",
    "PREC_VARS = {\n",
    "    'CESM2':    ('RAIN_FROM_ATM',  'SNOW_FROM_ATM'),\n",
    "    'CESM2_gw': ('RAIN_FROM_ATM',  'SNOW_FROM_ATM'),\n",
    "    'NorESM':   ('RAIN_FROM_ATM',  'SNOW_FROM_ATM'),\n",
    "    'E3SM':     ('RAIN',           'SNOW'),\n",
    "    'IPSL':     ('pr',),    # loader returns P already\n",
    "    'CNRM':     ('pr',),\n",
    "    'MIROC':    ('pr',),\n",
    "}\n",
    "\n",
    "# container for all precipitation datasets\n",
    "precip = {}\n",
    "\n",
    "for model, vars_ in PREC_VARS.items():\n",
    "    loader = MODEL_LOADERS[model]\n",
    "    # if we have separate rain & snow variables, fetch both & sum\n",
    "    if len(vars_) == 2:\n",
    "        rain_var, snow_var = vars_\n",
    "        irr_r = loader(rain_var)[0]  # [0] = IRR\n",
    "        noi_r = loader(rain_var)[1]  # [1] = NOI\n",
    "        irr_s = loader(snow_var)[0]\n",
    "        noi_s = loader(snow_var)[1]\n",
    "\n",
    "        precip[model] = {\n",
    "            'IRR': irr_r + irr_s,\n",
    "            'NOI': noi_r + noi_s\n",
    "        }\n",
    "    else:\n",
    "        # single var: loader returns precipitation directly\n",
    "        (var,) = vars_\n",
    "        irr_p, noi_p = loader(var)\n",
    "        precip[model] = {\n",
    "            'IRR': irr_p,\n",
    "            'NOI': noi_p\n",
    "        }\n",
    "\n",
    "# Example access:\n",
    "# IWW_IRR_1901_2014_CESM2_P   = precip['CESM2']['IRR']\n",
    "# IWW_NOI_1901_2014_CESM2_P   = precip['CESM2']['NOI']\n",
    "# IWW_IRR_1901_2014_E3SM_P    = precip['E3SM']['IRR']\n",
    "# IWW_NOI_1901_2014_MIROC_P   = precip['MIROC']['NOI']\n",
    "\n",
    "RUNOFF_VARS = {\n",
    "    'CESM2':    'QRUNOFF',\n",
    "    'CESM2_gw': 'QRUNOFF',\n",
    "    'NorESM':   'QRUNOFF',\n",
    "    'E3SM':     'QRUNOFF',\n",
    "    'IPSL':     'mrro',\n",
    "    'CNRM':     'mrro',\n",
    "    'MIROC':    'mrro',\n",
    "}\n",
    "\n",
    "# container for all runoff datasets\n",
    "runoff = {}\n",
    "\n",
    "for model, var in RUNOFF_VARS.items():\n",
    "    loader = MODEL_LOADERS[model]\n",
    "    irr_r, noi_r = loader(var)\n",
    "    runoff[model] = {\n",
    "        'IRR': irr_r,\n",
    "        'NOI': noi_r\n",
    "    }\n",
    "    \n",
    "\n",
    "ET_COMPONENTS = {\n",
    "    'CESM2':    ['QFLX_EVAP_TOT'],\n",
    "    'CESM2_gw': ['QFLX_EVAP_TOT'],\n",
    "    'NorESM':   ['QFLX_EVAP_TOT'],\n",
    "    'E3SM':     ['QSOIL', 'QVEGE', 'QVEGT'],\n",
    "    'IPSL':     ['evspsbl'],\n",
    "    'CNRM':     ['evspsbl'],\n",
    "    'MIROC':    ['evspsbl', 'tran'],\n",
    "}\n",
    "\n",
    "evapotran = {}\n",
    "\n",
    "for model, comps in ET_COMPONENTS.items():\n",
    "    loader = MODEL_LOADERS[model]\n",
    "    irr_parts = []\n",
    "    noi_parts = []\n",
    "\n",
    "    # load each component and accumulate\n",
    "    for var in comps:\n",
    "        irr_var, noi_var = loader(var)\n",
    "        irr_parts.append(irr_var)\n",
    "        noi_parts.append(noi_var)\n",
    "\n",
    "    # sum all parts to get total ET\n",
    "    total_irr = sum(irr_parts)\n",
    "    total_noi = sum(noi_parts)\n",
    "\n",
    "    evapotran[model] = {\n",
    "        'IRR': total_irr,\n",
    "        'NOI': total_noi\n",
    "    }\n",
    "    \n",
    "DATA_GROUPS = {\n",
    "    'P'  : precip,\n",
    "    'R'  : runoff,\n",
    "    'ET' : evapotran,\n",
    "}\n",
    "\n",
    "# Here we use CESM2 output for masking in case some models also output grid cells over the ocean\n",
    "\n",
    "for name, group in DATA_GROUPS.items():\n",
    "    # make mask from CESM2 IRR\n",
    "    ref_mask = np.isnan(group['CESM2']['IRR'])\n",
    "    # apply to every other model & both scenarios\n",
    "    for model, scen_dict in group.items():\n",
    "        if model == 'CESM2':\n",
    "            continue\n",
    "        for scen in ('IRR','NOI'):\n",
    "            scen_dict[scen][ref_mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729b56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcu_global_water(data): # This is the function to calculate global mean water fluxes (not used here in this script)\n",
    "    \n",
    "    str_area = str_base + '/plotting_tools/AREA.mat'\n",
    "    \n",
    "    area = get_data_from_mat(str_area, 'AREA')\n",
    "    \n",
    "    area_for_calcu = area.T\n",
    "    \n",
    "    area_for_calcu[np.isnan(data[0, :, :])] = np.nan\n",
    "    \n",
    "    \n",
    "    data_globe = data * AREA.T\n",
    "    \n",
    "    data_globe = np.nansum(data_globe, axis=(1, 2))\n",
    "    \n",
    "    area_for_calcu = np.nansum(area_for_calcu, axis=(0, 1))\n",
    "    \n",
    "    return data_globe/area_for_calcu\n",
    "\n",
    "def calcu_water_region(data, region_id): \n",
    "    \n",
    "    # This is the function to calculate regional mean water fluxes (used here)\n",
    "    \n",
    "    str_area = str_base + '/plotting_tools/AREA.mat'\n",
    "    \n",
    "    area = get_data_from_mat(str_area, 'AREA') \n",
    "    \n",
    "    # Area for CLM_data, we read it every time when calling this function\n",
    "    # Because in Jupyter notebook the array will be changed even though only being used in another function\n",
    "    \n",
    "    area_for_calcu = area.T\n",
    "    \n",
    "    # build a mask of all points to set to NaN\n",
    "    mask = (\n",
    "        np.isnan(data[0, :, :])                                    # missing data\n",
    "        | (np.abs(ar6_region - region_id) > 0.2)                   # outside [region_id–tol, region_id+tol]\n",
    "    )\n",
    "    \n",
    "    area_for_calcu[mask] = np.nan\n",
    "\n",
    "    # Keep only the area in the region\n",
    "    \n",
    "    data_region = data * area_for_calcu\n",
    "    \n",
    "    data_region[:, mask] = np.nan\n",
    "\n",
    "    data_region = np.nansum(data_region, axis=(1, 2))\n",
    "\n",
    "    area_for_calcu = np.nansum(area_for_calcu, axis=(0, 1))\n",
    "    \n",
    "    return data_region/area_for_calcu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676800ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We divide the whole period (114) years to six 19-year periods\n",
    "def get_19_years_mean(data):\n",
    "    data_1=np.mean(data[0:19])\n",
    "    data_2=np.mean(data[19:38])\n",
    "    data_3=np.mean(data[38:57])\n",
    "    data_4=np.mean(data[57:76])\n",
    "    data_5=np.mean(data[76:95])\n",
    "    data_6=np.mean(data[95:114])\n",
    "    return np.array([data_1,data_2,data_3,data_4,data_5,data_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad201937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regional_p(region_id):\n",
    "\n",
    "    \n",
    "    # 1. Define the models in the exact order you want them stacked\n",
    "    models = [\n",
    "        'CESM2',\n",
    "        'CESM2_gw',\n",
    "        'NorESM',\n",
    "        'E3SM',\n",
    "        'IPSL',\n",
    "        'MIROC',\n",
    "        'CNRM',\n",
    "    ]\n",
    "\n",
    "    # 2. Prepare empty lists to collect each model's IRR/NOI series\n",
    "    irr_list = []\n",
    "    noi_list = []\n",
    "\n",
    "    # 3. Loop once, calculate both series (using your helper), and append\n",
    "    for m in models:\n",
    "        irr = calcu_water_region(\n",
    "            precip[m]['IRR'],\n",
    "            region_id\n",
    "        )\n",
    "        noi = calcu_water_region(\n",
    "            precip[m]['NOI'],\n",
    "            region_id\n",
    "        )\n",
    "        \n",
    "        irr_list.append(irr)\n",
    "        noi_list.append(noi)\n",
    "\n",
    "    # 4. Stack them all in one go – same as your vstack calls\n",
    "    data_irr_p_et = np.vstack(irr_list)\n",
    "    data_noi_p_et = np.vstack(noi_list)\n",
    "\n",
    "    # 5. Compute the difference\n",
    "    data_diff_p_et = data_irr_p_et - data_noi_p_et\n",
    "    \n",
    "    return data_irr_p_et, data_noi_p_et, data_diff_p_et\n",
    "\n",
    "def get_regional_et(region_id):\n",
    "\n",
    "    \n",
    "    # 1. Define the models in the exact order you want them stacked\n",
    "    models = [\n",
    "        'CESM2',\n",
    "        'CESM2_gw',\n",
    "        'NorESM',\n",
    "        'E3SM',\n",
    "        'IPSL',\n",
    "        'MIROC',\n",
    "        'CNRM',\n",
    "    ]\n",
    "\n",
    "    # 2. Prepare empty lists to collect each model's IRR/NOI series\n",
    "    irr_list = []\n",
    "    noi_list = []\n",
    "\n",
    "    # 3. Loop once, calculate both series (using your helper), and append\n",
    "    for m in models:\n",
    "        irr = calcu_water_region(\n",
    "            evapotran[m]['IRR'],\n",
    "            region_id\n",
    "        )\n",
    "        noi = calcu_water_region(\n",
    "            evapotran[m]['NOI'],\n",
    "            region_id\n",
    "        )\n",
    "        \n",
    "        irr_list.append(irr)\n",
    "        noi_list.append(noi)\n",
    "\n",
    "    # 4. Stack them all in one go – same as your vstack calls\n",
    "    data_irr_p_et = np.vstack(irr_list)\n",
    "    data_noi_p_et = np.vstack(noi_list)\n",
    "\n",
    "    # 5. Compute the difference\n",
    "    data_diff_p_et = data_irr_p_et - data_noi_p_et\n",
    "    \n",
    "    return data_irr_p_et, data_noi_p_et, data_diff_p_et\n",
    "\n",
    "def get_regional_r(region_id):\n",
    "\n",
    "    \n",
    "    # 1. Define the models in the exact order you want them stacked\n",
    "    models = [\n",
    "        'CESM2',\n",
    "        'CESM2_gw',\n",
    "        'NorESM',\n",
    "        'E3SM',\n",
    "        'IPSL',\n",
    "        'MIROC',\n",
    "        'CNRM',\n",
    "    ]\n",
    "\n",
    "    # 2. Prepare empty lists to collect each model's IRR/NOI series\n",
    "    irr_list = []\n",
    "    noi_list = []\n",
    "\n",
    "    # 3. Loop once, calculate both series (using your helper), and append\n",
    "    for m in models:\n",
    "        irr = calcu_water_region(\n",
    "            runoff[m]['IRR'],\n",
    "            region_id\n",
    "        )\n",
    "        noi = calcu_water_region(\n",
    "            runoff[m]['NOI'],\n",
    "            region_id\n",
    "        )\n",
    "        \n",
    "        irr_list.append(irr)\n",
    "        noi_list.append(noi)\n",
    "\n",
    "    # 4. Stack them all in one go – same as your vstack calls\n",
    "    data_irr_p_et = np.vstack(irr_list)\n",
    "    data_noi_p_et = np.vstack(noi_list)\n",
    "\n",
    "    # 5. Compute the difference\n",
    "    data_diff_p_et = data_irr_p_et - data_noi_p_et\n",
    "    \n",
    "    return data_irr_p_et, data_noi_p_et, data_diff_p_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c601aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) map your region names → AR6 IDs\n",
    "REGIONS = {\n",
    "    'SAS': 38,\n",
    "    'MED': 20,\n",
    "    'CNA':  5,\n",
    "    'WCA': 33,\n",
    "}\n",
    "\n",
    "def compute_stats(arr: np.ndarray, axis=0) -> dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Return the 25th, 50th, 75th percentiles and mean of `arr` along `axis`.\n",
    "    \"\"\"\n",
    "    pcts = np.percentile(arr, [25, 50, 75], axis=axis)\n",
    "    return {\n",
    "        'p25': get_19_years_mean(pcts[0]),\n",
    "        'p50': get_19_years_mean(pcts[1]),\n",
    "        'p75': get_19_years_mean(pcts[2]),\n",
    "        'mean': get_19_years_mean(np.mean(arr, axis=axis)),\n",
    "    }\n",
    "\n",
    "def batch_regional_stats_p(regions: dict[str,int]):\n",
    "    \"\"\"\n",
    "    For each region in `regions`, call get_regional_P_E and compute stats\n",
    "    for IRR, NOI, and their difference.\n",
    "    Returns a nested dict: stats[region]['irr']['p75'], etc.\n",
    "    \"\"\"\n",
    "    stats: dict[str, dict[str, dict[str, np.ndarray]]] = {}\n",
    "\n",
    "    for name, rid in regions.items():\n",
    "        irr_arr, noi_arr, diff_arr = get_regional_p(rid)\n",
    "\n",
    "        stats[name] = {\n",
    "            'irr':  compute_stats(irr_arr),\n",
    "            'noi':  compute_stats(noi_arr),\n",
    "            'diff': compute_stats(diff_arr),\n",
    "        }\n",
    "\n",
    "    return stats\n",
    "\n",
    "def batch_regional_stats_et(regions: dict[str,int]):\n",
    "    \"\"\"\n",
    "    For each region in `regions`, call get_regional_P_E and compute stats\n",
    "    for IRR, NOI, and their difference.\n",
    "    Returns a nested dict: stats[region]['irr']['p75'], etc.\n",
    "    \"\"\"\n",
    "    stats: dict[str, dict[str, dict[str, np.ndarray]]] = {}\n",
    "\n",
    "    for name, rid in regions.items():\n",
    "        irr_arr, noi_arr, diff_arr = get_regional_et(rid)\n",
    "\n",
    "        stats[name] = {\n",
    "            'irr':  compute_stats(irr_arr),\n",
    "            'noi':  compute_stats(noi_arr),\n",
    "            'diff': compute_stats(diff_arr),\n",
    "        }\n",
    "\n",
    "    return stats\n",
    "\n",
    "def batch_regional_stats_r(regions: dict[str,int]):\n",
    "    \"\"\"\n",
    "    For each region in `regions`, call get_regional_P_E and compute stats\n",
    "    for IRR, NOI, and their difference.\n",
    "    Returns a nested dict: stats[region]['irr']['p75'], etc.\n",
    "    \"\"\"\n",
    "    stats: dict[str, dict[str, dict[str, np.ndarray]]] = {}\n",
    "\n",
    "    for name, rid in regions.items():\n",
    "        irr_arr, noi_arr, diff_arr = get_regional_r(rid)\n",
    "\n",
    "        stats[name] = {\n",
    "            'irr':  compute_stats(irr_arr),\n",
    "            'noi':  compute_stats(noi_arr),\n",
    "            'diff': compute_stats(diff_arr),\n",
    "        }\n",
    "\n",
    "    return stats\n",
    "\n",
    "# run it once\n",
    "region_stats_p = batch_regional_stats_p(REGIONS)\n",
    "region_stats_et = batch_regional_stats_et(REGIONS)\n",
    "region_stats_r = batch_regional_stats_r(REGIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12),dpi=300)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4, left = 0.05, right = 0.95, top = 0.95, bottom = 0.05)\n",
    "ax1 = plt.subplot(431, frameon=True)\n",
    "# ax1.spines['top'].set_visible(False)\n",
    "# ax1.spines['right'].set_visible(False)\n",
    "X = np.array([1910, 1929, 1948, 1967, 1986, 2005])\n",
    "plt.bar(X-3, region_stats_p['SAS']['irr']['mean'], yerr=[region_stats_p['SAS']['irr']['mean']-region_stats_p['SAS']['irr']['p25'], region_stats_p['SAS']['irr']['p75']-region_stats_p['SAS']['irr']['mean']], width = 6, color='dodgerblue', capsize=6,label='P tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_p['SAS']['noi']['mean'], yerr=[region_stats_p['SAS']['noi']['mean']-region_stats_p['SAS']['noi']['p25'], region_stats_p['SAS']['noi']['p75']-region_stats_p['SAS']['noi']['mean']], width = 6, color='aqua', capsize=6,label='P 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('P (mm/year)', fontsize=12)\n",
    "plt.title('South Asia', fontsize=14, loc='center')\n",
    "plt.title('a', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(432, frameon=True)\n",
    "plt.bar(X-3, region_stats_et['SAS']['irr']['mean'], yerr=[region_stats_et['SAS']['irr']['mean']-region_stats_et['SAS']['irr']['p25'], region_stats_et['SAS']['irr']['p75']-region_stats_et['SAS']['irr']['mean']], width = 6, color='tomato', capsize=6,label='ET tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_et['SAS']['noi']['mean'], yerr=[region_stats_et['SAS']['noi']['mean']-region_stats_et['SAS']['noi']['p25'], region_stats_et['SAS']['noi']['p75']-region_stats_et['SAS']['noi']['mean']], width = 6, color='darksalmon', capsize=6,label='ET 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('ET (mm/year)', fontsize=12)\n",
    "plt.title('South Asia', fontsize=14, loc='center')\n",
    "plt.title('b', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(433, frameon=True)\n",
    "plt.bar(X-3, region_stats_r['SAS']['irr']['mean'], yerr=[region_stats_r['SAS']['irr']['mean']-region_stats_r['SAS']['irr']['p25'], region_stats_r['SAS']['irr']['p75']-region_stats_r['SAS']['irr']['mean']], width = 6, color='lime', capsize=6,label='R tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_r['SAS']['noi']['mean'], yerr=[region_stats_r['SAS']['noi']['mean']-region_stats_r['SAS']['noi']['p25'], region_stats_r['SAS']['noi']['p75']-region_stats_r['SAS']['noi']['mean']], width = 6, color='lightgreen', capsize=6,label='R 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('R (mm/year)', fontsize=12)\n",
    "plt.title('South Asia', fontsize=14, loc='center')\n",
    "plt.title('c', fontsize=14, loc='left')\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(434, frameon=True)\n",
    "plt.bar(X-3, region_stats_p['MED']['irr']['mean'], yerr=[region_stats_p['MED']['irr']['mean']-region_stats_p['MED']['irr']['p25'], region_stats_p['MED']['irr']['p75']-region_stats_p['MED']['irr']['mean']], width = 6, color='dodgerblue', capsize=6,label='P tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_p['MED']['noi']['mean'], yerr=[region_stats_p['MED']['noi']['mean']-region_stats_p['MED']['noi']['p25'], region_stats_p['MED']['noi']['p75']-region_stats_p['MED']['noi']['mean']], width = 6, color='aqua', capsize=6,label='P 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('P (mm/year)', fontsize=12)\n",
    "plt.title('Mediterranean', fontsize=14, loc='center')\n",
    "plt.title('d', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(435, frameon=True)\n",
    "plt.bar(X-3, region_stats_et['MED']['irr']['mean'], yerr=[region_stats_et['MED']['irr']['mean']-region_stats_et['MED']['irr']['p25'], region_stats_et['MED']['irr']['p75']-region_stats_et['MED']['irr']['mean']], width = 6, color='tomato', capsize=6,label='ET tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_et['MED']['noi']['mean'], yerr=[region_stats_et['MED']['noi']['mean']-region_stats_et['MED']['noi']['p25'], region_stats_et['MED']['noi']['p75']-region_stats_et['MED']['noi']['mean']], width = 6, color='darksalmon', capsize=6,label='ET 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('ET (mm/year)', fontsize=12)\n",
    "plt.title('Mediterranean', fontsize=14, loc='center')\n",
    "plt.title('e', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(436, frameon=True)\n",
    "plt.bar(X-3, region_stats_r['MED']['irr']['mean'], yerr=[region_stats_r['MED']['irr']['mean']-region_stats_r['MED']['irr']['p25'], region_stats_r['MED']['irr']['p75']-region_stats_r['MED']['irr']['mean']], width = 6, color='lime', capsize=6,label='R tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_r['MED']['noi']['mean'], yerr=[region_stats_r['MED']['noi']['mean']-region_stats_r['MED']['noi']['p25'], region_stats_r['MED']['noi']['p75']-region_stats_r['MED']['noi']['mean']], width = 6, color='lightgreen', capsize=6,label='R 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('R (mm/year)', fontsize=12)\n",
    "plt.title('Mediterranean', fontsize=14, loc='center')\n",
    "plt.title('f', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(437, frameon=True)\n",
    "plt.bar(X-3, region_stats_p['CNA']['irr']['mean'], yerr=[region_stats_p['CNA']['irr']['mean']-region_stats_p['CNA']['irr']['p25'], region_stats_p['CNA']['irr']['p75']-region_stats_p['CNA']['irr']['mean']], width = 6, color='dodgerblue', capsize=6,label='P tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_p['CNA']['noi']['mean'], yerr=[region_stats_p['CNA']['noi']['mean']-region_stats_p['CNA']['noi']['p25'], region_stats_p['CNA']['noi']['p75']-region_stats_p['CNA']['noi']['mean']], width = 6, color='aqua', capsize=6,label='P 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('P (mm/year)', fontsize=12)\n",
    "plt.title('Central North America', fontsize=14, loc='center')\n",
    "plt.title('g', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(438, frameon=True)\n",
    "plt.bar(X-3, region_stats_et['CNA']['irr']['mean'], yerr=[region_stats_et['CNA']['irr']['mean']-region_stats_et['CNA']['irr']['p25'], region_stats_et['CNA']['irr']['p75']-region_stats_et['CNA']['irr']['mean']], width = 6, color='tomato', capsize=6,label='ET tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_et['CNA']['noi']['mean'], yerr=[region_stats_et['CNA']['noi']['mean']-region_stats_et['CNA']['noi']['p25'], region_stats_et['CNA']['noi']['p75']-region_stats_et['CNA']['noi']['mean']], width = 6, color='darksalmon', capsize=6,label='ET 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('ET (mm/year)', fontsize=12)\n",
    "plt.title('Central North America', fontsize=14, loc='center')\n",
    "plt.title('h', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(439, frameon=True)\n",
    "plt.bar(X-3, region_stats_r['CNA']['irr']['mean'], yerr=[region_stats_r['CNA']['irr']['mean']-region_stats_r['CNA']['irr']['p25'], region_stats_r['CNA']['irr']['p75']-region_stats_r['CNA']['irr']['mean']], width = 6, color='lime', capsize=6,label='R tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_r['CNA']['noi']['mean'], yerr=[region_stats_r['CNA']['noi']['mean']-region_stats_r['CNA']['noi']['p25'], region_stats_r['CNA']['noi']['p75']-region_stats_r['CNA']['noi']['mean']], width = 6, color='lightgreen', capsize=6,label='R 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('R (mm/year)', fontsize=12)\n",
    "plt.title('Central North America', fontsize=14, loc='center')\n",
    "plt.title('i', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(4,3,10, frameon=True)\n",
    "plt.bar(X-3, region_stats_p['WCA']['irr']['mean'], yerr=[region_stats_p['WCA']['irr']['mean']-region_stats_p['WCA']['irr']['p25'], region_stats_p['WCA']['irr']['p75']-region_stats_p['WCA']['irr']['mean']], width = 6, color='dodgerblue', capsize=6,label='P tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_p['WCA']['noi']['mean'], yerr=[region_stats_p['WCA']['noi']['mean']-region_stats_p['WCA']['noi']['p25'], region_stats_p['WCA']['noi']['p75']-region_stats_p['WCA']['noi']['mean']], width = 6, color='aqua', capsize=6,label='P 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('P (mm/year)', fontsize=12)\n",
    "plt.title('West Central Asia', fontsize=14, loc='center')\n",
    "plt.title('j', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(4,3,11, frameon=True)\n",
    "plt.bar(X-3, region_stats_et['WCA']['irr']['mean'], yerr=[region_stats_et['WCA']['irr']['mean']-region_stats_et['WCA']['irr']['p25'], region_stats_et['WCA']['irr']['p75']-region_stats_et['WCA']['irr']['mean']], width = 6, color='tomato', capsize=6,label='ET tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_et['WCA']['noi']['mean'], yerr=[region_stats_et['WCA']['noi']['mean']-region_stats_et['WCA']['noi']['p25'], region_stats_et['WCA']['noi']['p75']-region_stats_et['WCA']['noi']['mean']], width = 6, color='darksalmon', capsize=6,label='ET 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('ET (mm/year)', fontsize=12)\n",
    "plt.title('West Central Asia', fontsize=14, loc='center')\n",
    "plt.title('k', fontsize=14, loc='left')\n",
    "\n",
    "ax1 = plt.subplot(4,3,12, frameon=True)\n",
    "plt.bar(X-3, region_stats_r['WCA']['irr']['mean'], yerr=[region_stats_r['WCA']['irr']['mean']-region_stats_r['WCA']['irr']['p25'], region_stats_r['WCA']['irr']['p75']-region_stats_r['WCA']['irr']['mean']], width = 6, color='lime', capsize=6,label='R tranirr',alpha=0.8)\n",
    "plt.bar(X+3, region_stats_r['WCA']['noi']['mean'], yerr=[region_stats_r['WCA']['noi']['mean']-region_stats_r['WCA']['noi']['p25'], region_stats_r['WCA']['noi']['p75']-region_stats_r['WCA']['noi']['mean']], width = 6, color='lightgreen', capsize=6,label='R 1901irr',alpha=0.8)\n",
    "plt.xticks(X, ['I','II','III','IV','V','VI'], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.legend(fontsize=10, loc='lower right')\n",
    "plt.xlim(1901, 2015)\n",
    "plt.ylabel('R (mm/year)', fontsize=12)\n",
    "plt.title('West Central Asia', fontsize=14, loc='center')\n",
    "plt.title('l', fontsize=14, loc='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc1720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
